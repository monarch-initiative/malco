{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T20:14:26.101006Z",
     "start_time": "2024-09-24T20:14:25.106019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                problem  \\\n0     I am running an experiment on a clinical case ...   \n1     I am running an experiment on a clinical case ...   \n2     I am running an experiment on a clinical case ...   \n3     I am running an experiment on a clinical case ...   \n4     I am running an experiment on a clinical case ...   \n...                                                 ...   \n5262  I am running an experiment on a clinical case ...   \n5263  I am running an experiment on a clinical case ...   \n5264  I am running an experiment on a clinical case ...   \n5265  I am running an experiment on a clinical case ...   \n5266  I am running an experiment on a clinical case ...   \n\n                                         service_answer  \\\n0     I'm sorry, but I cannot generate a differentia...   \n1     1. VACTERL association \\n2. Feingold syndrome ...   \n2     1. Autosomal recessive hyper-IgE syndrome (DOC...   \n3     1. Sclerosteosis \\n2. Van Buchem disease \\n3. ...   \n4     1. Smith-Lemli-Opitz syndrome \\n2. ATR-X syndr...   \n...                                                 ...   \n5262  1. Wolfram syndrome \\n2. Alström syndrome \\n3....   \n5263  1. GM1 gangliosidosis \\n2. Galactosialidosis \\...   \n5264  1. Mitochondrial neurogastrointestinal encepha...   \n5265  1. Down syndrome\\n2. Kabuki syndrome \\n3. 22q1...   \n5266  1. Medium-chain acyl-CoA dehydrogenase deficie...   \n\n                                               metadata  \n0     PMID_34722527_individual_103_7_Hui_Wang_Compre...  \n1              PMID_32730804_Individual_3_en-prompt.txt  \n2               PMID_19776401_Patient_6_1_en-prompt.txt  \n3                 PMID_20358596_Patient_A_en-prompt.txt  \n4                         PMID_36586412_8_en-prompt.txt  \n...                                                 ...  \n5262  PMID_9817917_Family_4_individual_13070_en-prom...  \n5263                      PMID_1907800_TS_en-prompt.txt  \n5264            PMID_28673863_28673863_P1_en-prompt.txt  \n5265   PMID_31021519_individual_SATB2_112_en-prompt.txt  \n5266  PMID_33045405_Liu_et_al___2019__patient_1_en-p...  \n\n[5267 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>problem</th>\n      <th>service_answer</th>\n      <th>metadata</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I am running an experiment on a clinical case ...</td>\n      <td>I'm sorry, but I cannot generate a differentia...</td>\n      <td>PMID_34722527_individual_103_7_Hui_Wang_Compre...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I am running an experiment on a clinical case ...</td>\n      <td>1. VACTERL association \\n2. Feingold syndrome ...</td>\n      <td>PMID_32730804_Individual_3_en-prompt.txt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I am running an experiment on a clinical case ...</td>\n      <td>1. Autosomal recessive hyper-IgE syndrome (DOC...</td>\n      <td>PMID_19776401_Patient_6_1_en-prompt.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I am running an experiment on a clinical case ...</td>\n      <td>1. Sclerosteosis \\n2. Van Buchem disease \\n3. ...</td>\n      <td>PMID_20358596_Patient_A_en-prompt.txt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I am running an experiment on a clinical case ...</td>\n      <td>1. Smith-Lemli-Opitz syndrome \\n2. ATR-X syndr...</td>\n      <td>PMID_36586412_8_en-prompt.txt</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5262</th>\n      <td>I am running an experiment on a clinical case ...</td>\n      <td>1. Wolfram syndrome \\n2. Alström syndrome \\n3....</td>\n      <td>PMID_9817917_Family_4_individual_13070_en-prom...</td>\n    </tr>\n    <tr>\n      <th>5263</th>\n      <td>I am running an experiment on a clinical case ...</td>\n      <td>1. GM1 gangliosidosis \\n2. Galactosialidosis \\...</td>\n      <td>PMID_1907800_TS_en-prompt.txt</td>\n    </tr>\n    <tr>\n      <th>5264</th>\n      <td>I am running an experiment on a clinical case ...</td>\n      <td>1. Mitochondrial neurogastrointestinal encepha...</td>\n      <td>PMID_28673863_28673863_P1_en-prompt.txt</td>\n    </tr>\n    <tr>\n      <th>5265</th>\n      <td>I am running an experiment on a clinical case ...</td>\n      <td>1. Down syndrome\\n2. Kabuki syndrome \\n3. 22q1...</td>\n      <td>PMID_31021519_individual_SATB2_112_en-prompt.txt</td>\n    </tr>\n    <tr>\n      <th>5266</th>\n      <td>I am running an experiment on a clinical case ...</td>\n      <td>1. Medium-chain acyl-CoA dehydrogenase deficie...</td>\n      <td>PMID_33045405_Liu_et_al___2019__patient_1_en-p...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5267 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# we start with o1 responses here:\n",
    "o1_responses = pd.read_csv('../supplemental_data/gpt_o1_response/gpt_o1_response.csv', index_col=0)\n",
    "o1_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import re\n",
    "from oaklib.interfaces.text_annotator_interface import TextAnnotationConfiguration\n",
    "from oaklib.interfaces.text_annotator_interface import TextAnnotatorInterface\n",
    "import logging\n",
    "from typing import Tuple, List\n",
    "\n",
    "# Compile a regex pattern to detect lines starting with \"Differential Diagnosis:\"\n",
    "dd_re = re.compile(r\"^[^A-z]*Differential Diagnosis\")\n",
    "related_re = re.compile(r'\\s*\\S+\\-related\\s*')  # Pattern to detect \"something-related\"\n",
    "\n",
    "# General terms to exclude when doing inexact matching. \n",
    "# These are MONDO:0700096 human disease and its immediate subclasses\n",
    "default_exclude_list = [\n",
    "    \"MONDO:0700096\", # human disease\n",
    "    \"MONDO:0002022\", \"MONDO:0002025\", \"MONDO:0002051\", \"MONDO:0002081\", \"MONDO:0002118\",\n",
    "    \"MONDO:0002254\", \"MONDO:0002409\", \"MONDO:0002657\", \"MONDO:0003847\", \"MONDO:0003900\",\n",
    "    \"MONDO:0004335\", \"MONDO:0004995\", \"MONDO:0005039\", \"MONDO:0005046\", \"MONDO:0005066\",\n",
    "    \"MONDO:0005071\", \"MONDO:0005087\", \"MONDO:0005137\", \"MONDO:0005151\", \"MONDO:0005550\",\n",
    "    \"MONDO:0005570\", \"MONDO:0006858\", \"MONDO:0019040\", \"MONDO:0019303\", \"MONDO:0020683\",\n",
    "    \"MONDO:0021147\", \"MONDO:0021166\", \"MONDO:0021669\", \"MONDO:0024458\", \"MONDO:0024623\",\n",
    "    \"MONDO:0029000\", \"MONDO:0043459\", \"MONDO:0043543\", \"MONDO:0043839\", \"MONDO:0044970\",\n",
    "    \"MONDO:0044991\", \"MONDO:0045024\", \"MONDO:0100086\", \"MONDO:0100366\", \"MONDO:0700003\",\n",
    "    \"MONDO:0700007\", \"MONDO:0700220\"\n",
    "]\n",
    "\n",
    "# Function to clean and remove \"Differential Diagnosis\" header if present\n",
    "def clean_service_answer(answer: str) -> str:\n",
    "    \"\"\"Remove the 'Differential Diagnosis' header if present, and clean the first line.\"\"\"\n",
    "    lines = answer.split('\\n')\n",
    "    # Filter out any line that starts with \"Differential Diagnosis:\"\n",
    "    cleaned_lines = [line for line in lines if not dd_re.match(line)]\n",
    "    return '\\n'.join(cleaned_lines)\n",
    "\n",
    "# Clean the diagnosis line by removing leading numbers, periods, asterisks, and spaces\n",
    "def clean_diagnosis_line(line: str) -> str:\n",
    "    \"\"\"Remove leading numbers, asterisks, and unnecessary punctuation/spaces from the diagnosis.\"\"\"\n",
    "    line = re.sub(r'^\\**\\d+\\.\\s*', '', line)  # Remove leading numbers and periods\n",
    "    line = line.strip('*')  # Remove asterisks around the text\n",
    "    return line.strip()  # Strip any remaining spaces\n",
    "\n",
    "# Split a diagnosis into its main name and synonym if present\n",
    "def split_diagnosis_and_synonym(diagnosis: str) -> Tuple[str, str]:\n",
    "    \"\"\"Split the diagnosis into main name and synonym (if present in parentheses).\"\"\"\n",
    "    match = re.match(r'^(.*)\\s*\\((.*)\\)\\s*$', diagnosis)\n",
    "    if match:\n",
    "        main_diagnosis, synonym = match.groups()\n",
    "        return main_diagnosis.strip(), synonym.strip()\n",
    "    return diagnosis, None  # Return the original diagnosis if no synonym is found\n",
    "\n",
    "# Remove the \"-related\" part of the diagnosis if present\n",
    "def strip_related_phrase(diagnosis: str) -> str:\n",
    "    \"\"\"Remove the '[anything]-related' part from the beginning of the diagnosis.\"\"\"\n",
    "    return related_re.sub('', diagnosis).strip()\n",
    "\n",
    "# Perform grounding on the text to MONDO ontology and return the result\n",
    "def perform_grounding(\n",
    "    annotator: TextAnnotatorInterface,\n",
    "    diagnosis: str,\n",
    "    exact_match: bool = True,\n",
    "    verbose: bool = False,\n",
    "    include_list: List[str] = [\"MONDO:\"],\n",
    "    exclude_list: List[str] = default_exclude_list\n",
    ") -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Perform grounding for a diagnosis. The 'exact_match' flag controls whether exact or inexact\n",
    "    (partial) matching is used. Filter results to include only CURIEs that match the 'include_list',\n",
    "    and exclude results that match the 'exclude_list'.\n",
    "    Remove redundant groundings from the result.\n",
    "    \"\"\"\n",
    "    config = TextAnnotationConfiguration(matches_whole_text=exact_match)\n",
    "    annotations = list(annotator.annotate_text(diagnosis, configuration=config))\n",
    "\n",
    "    # Filter and remove duplicates, while excluding unwanted general terms\n",
    "    filtered_annotations = list(\n",
    "        {\n",
    "            (ann.object_id, ann.object_label)\n",
    "            for ann in annotations\n",
    "            if any(ann.object_id.startswith(prefix) for prefix in include_list)\n",
    "            and ann.object_id not in exclude_list\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if filtered_annotations:\n",
    "        return filtered_annotations\n",
    "    else:\n",
    "        match_type = \"exact\" if exact_match else \"inexact\"\n",
    "        if verbose:\n",
    "            logging.warning(f\"No {match_type} grounded IDs found for: {diagnosis}\")\n",
    "        return [('N/A', 'No grounding found')]\n",
    "\n",
    "# Ground the diagnosis text to MONDO ontology\n",
    "def ground_diagnosis_text_to_mondo(\n",
    "    annotator: TextAnnotatorInterface,\n",
    "    differential_diagnosis: str,\n",
    "    verbose: bool = False,\n",
    "    include_list: List[str] = [\"MONDO:\"],\n",
    "    exclude_list: List[str] = default_exclude_list\n",
    ") -> List[Tuple[str, List[Tuple[str, str]]]]:\n",
    "    results = []\n",
    "    \n",
    "    # Split the input into lines and process each one\n",
    "    for line in differential_diagnosis.splitlines():\n",
    "        clean_line = clean_diagnosis_line(line)\n",
    "        \n",
    "        # Skip header lines like \"**Differential diagnosis:**\"\n",
    "        if not clean_line or \"Differential diagnosis\" in clean_line.lower():\n",
    "            continue\n",
    "        \n",
    "        # Try grounding the full line first (exact match)\n",
    "        grounded = perform_grounding(annotator, clean_line, exact_match=True, verbose=verbose, include_list=include_list, exclude_list=exclude_list)\n",
    "        \n",
    "        # If grounding fails and there is a synonym (text with parentheses), split and ground both parts\n",
    "        if grounded == [('N/A', 'No grounding found')]:\n",
    "            main_diagnosis, synonym = split_diagnosis_and_synonym(clean_line)\n",
    "            if synonym:\n",
    "                main_grounded = perform_grounding(annotator, main_diagnosis, exact_match=True, verbose=verbose, include_list=include_list, exclude_list=exclude_list)\n",
    "                synonym_grounded = perform_grounding(annotator, synonym, exact_match=True, verbose=verbose, include_list=include_list, exclude_list=exclude_list)\n",
    "                # Combine the results if any of them found results\n",
    "                if main_grounded != [('N/A', 'No grounding found')] or synonym_grounded != [('N/A', 'No grounding found')]:\n",
    "                    grounded = main_grounded + synonym_grounded\n",
    "                    grounded = list(set(grounded))  # Remove duplicates\n",
    "        \n",
    "        # If the diagnosis contains \"-related\", try stripping it and exact matching again\n",
    "        if grounded == [('N/A', 'No grounding found')] and related_re.search(clean_line):\n",
    "            stripped_line = strip_related_phrase(clean_line)\n",
    "            grounded = perform_grounding(annotator, stripped_line, exact_match=True, verbose=verbose, include_list=include_list, exclude_list=exclude_list)\n",
    "\n",
    "        # If neither the main diagnosis, the synonym, nor the stripped \"-related\" version could be grounded, try inexact matching\n",
    "        if grounded == [('N/A', 'No grounding found')]:\n",
    "            if verbose:\n",
    "                logging.warning(f\"Exact grounding failed for: {clean_line}, attempting inexact match.\")\n",
    "            grounded = perform_grounding(annotator, clean_line, exact_match=False, verbose=verbose, include_list=include_list, exclude_list=exclude_list)\n",
    "        \n",
    "        # If still no grounding is found, log the final failure\n",
    "        if grounded == [('N/A', 'No grounding found')]:\n",
    "            if verbose:\n",
    "                logging.warning(f\"Final grounding failed for: {clean_line}\")\n",
    "        \n",
    "        # Append the grounded results (even if no grounding was found)\n",
    "        results.append((clean_line, grounded))\n",
    "\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T20:14:28.974307Z",
     "start_time": "2024-09-24T20:14:26.105673Z"
    }
   },
   "id": "16ba761d188542d4"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Get the OAK annotator for MONDO\n",
    "from oaklib import get_adapter\n",
    "# Set up OAK SQLite implementation for MONDO\n",
    "annotator = get_adapter(\"sqlite:obo:mondo\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T20:14:29.004136Z",
     "start_time": "2024-09-24T20:14:28.974574Z"
    }
   },
   "id": "9392ad744520e204"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##\n",
    "## RUN SOME TESTS\n",
    "##\n",
    "\n",
    "# Example grounding with OAK annotation - testing on a sample input\n",
    "differential_diagnosis_text = \"\"\"\n",
    "**Differential Diagnosis:**\n",
    "1. Branchiooculofacial syndrome\n",
    "2. Unicorn syndrome\n",
    "3. Cystic fibrosis\n",
    "4. 22q11.2 deletion syndrome (Velocardiofacial syndrome)\n",
    "**5. ATP6V0A4-related distal renal tubular acidosis**\n",
    "\"\"\"\n",
    "\n",
    "# Cleaning and grounding the sample differential diagnosis text\n",
    "cleaned_text = clean_service_answer(differential_diagnosis_text)\n",
    "# Assert that the cleaning process returns non-empty text\n",
    "assert cleaned_text != \"\", \"Cleaning failed: the cleaned text is empty.\"\n",
    "\n",
    "# Define the expected result for the sample input\n",
    "expected_result = [\n",
    "    ('Branchiooculofacial syndrome', [('MONDO:0007235', 'branchiooculofacial syndrome')]), \n",
    "    ('Unicorn syndrome', [('N/A', 'No grounding found')]), \n",
    "    ('Cystic fibrosis', [('MONDO:0009061', 'cystic fibrosis')]), \n",
    "    ('22q11.2 deletion syndrome (Velocardiofacial syndrome)', [\n",
    "        ('MONDO:0018923', '22q11.2 deletion syndrome'), \n",
    "        ('MONDO:0008564', 'DiGeorge syndrome'), \n",
    "        ('MONDO:0008644', 'velocardiofacial syndrome')\n",
    "    ]), \n",
    "    ('ATP6V0A4-related distal renal tubular acidosis', [('MONDO:0015827', 'distal renal tubular acidosis')])\n",
    "]\n",
    "\n",
    "# Ground the cleaned text to MONDO\n",
    "result = ground_diagnosis_text_to_mondo(annotator, cleaned_text, verbose=False)\n",
    "print(\"Grounding Result:\")\n",
    "print(result)\n",
    "\n",
    "# Assert that the grounded result matches the expected output\n",
    "assert len(result) == len(expected_result), \"Grounding result length does not match expected result length\"\n",
    "\n",
    "for res_item, expected_item in zip(result, expected_result):\n",
    "    # First, assert that the diagnosis name matches exactly\n",
    "    assert res_item[0] == expected_item[0], f\"Diagnosis mismatch: {res_item[0]} != {expected_item[0]}\"\n",
    "    \n",
    "    # Then, assert that the grounding list matches, ignoring order\n",
    "    assert set(res_item[1]) == set(expected_item[1]), f\"Grounding mismatch for {res_item[0]}\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-09-24T20:14:29.006891Z"
    }
   },
   "id": "93344674133a1015"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Apply the cleaning and grounding functions directly to the 'service_answer' column with progress bar\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Now you can use progress_apply\n",
    "o1_responses['grounded_diagnosis'] = o1_responses['service_answer'].progress_apply(\n",
    "    lambda x: ground_diagnosis_text_to_mondo(annotator, clean_service_answer(x), verbose=False)\n",
    ")\n",
    "\n",
    "# Save the DataFrame with the new 'grounded_diagnosis' column to a CSV file\n",
    "output_file = '../supplemental_data/gpt_o1_response/gpt_o1_response_grounded.csv'\n",
    "o1_responses.to_csv(output_file, index=False)\n",
    "\n",
    "# Display a sample of the updated DataFrame\n",
    "o1_responses.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "57623eb7c45853e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Count the number of items with no grounding found (about 1.6%)\n",
    "#  grep -v \"I'm sorry\" ../supplemental_data/gpt_o1_response/gpt_o1_response_grounded.csv | grep -o \"No grounding found\" | wc -l \n",
    "#  551\n",
    "# (.venv) ~/PythonProject/malco/notebooks short_letter $ grep -o \"('MONDO:[^']*', '[^']*')\" ../supplemental_data/gpt_o1_response/gpt_o1_response_grounded.csv | wc -l\n",
    "# Compare to the number of grounded items:\n",
    "# 34539\n",
    "# so about 98.4% of the items are grounded.\n",
    "\n",
    "# We'll need to run these through OntoGPT I think"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7b73299a02a38f28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the DataFrame with the grounded diagnosis text (not using o1_responses from above to avoid re-running the previous cell)\n",
    "o1_responses = pd.read_csv('../supplemental_data/gpt_o1_response/gpt_o1_response_grounded.csv')\n",
    "o1_responses"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "22f84b14277bd22f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Initialize an empty dictionary to store the result\n",
    "correct_answers_dict = {}\n",
    "\n",
    "# Define the file path\n",
    "file_path = '../supplemental_data/correct_results.tsv'\n",
    "\n",
    "# Read the TSV file and populate the dictionary\n",
    "with open(file_path, 'r', newline='') as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        # Assign each column to the corresponding variable\n",
    "        correct_disease_name = row[0]\n",
    "        correct_ID = row[1]\n",
    "        prompt_file_name = row[2]\n",
    "        \n",
    "        # Populate the dictionary\n",
    "        correct_answers_dict[prompt_file_name] = (correct_ID, correct_disease_name)\n",
    "\n",
    "correct_answers_dict"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ee41889dc2a0e16a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from malco.post_process.mondo_score_utils import score_grounded_result\n",
    "import warnings\n",
    "import csv\n",
    "import ast\n",
    "from oaklib import get_adapter\n",
    "from pathlib import Path\n",
    "\n",
    "dont_nuke_existing_output = False\n",
    "\n",
    "# Create the directory if it doesn't exist; if it does, raise an error\n",
    "output_dir = Path(\"../outputdir_all_2024_07_04/gpt_o1_disease_results\")\n",
    "if output_dir.exists():\n",
    "    if dont_nuke_existing_output:\n",
    "        raise FileExistsError(f\"Directory {output_dir} already exists. Please remove it first.\")\n",
    "    else:\n",
    "        warnings.warn(f\"Directory {output_dir} already exists. Existing files may be overwritten.\")\n",
    "else:\n",
    "    output_dir.mkdir(parents=True)\n",
    "\n",
    "# Function to write results to a file\n",
    "def write_result_to_file(file_path, results):\n",
    "    with open(file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        # Write header\n",
    "        writer.writerow([\"rank\", \"disease_name\", \"disease_identifier\", \"correct_ID\", \"grounded_score\", \"is_correct\"])\n",
    "        # Write each result\n",
    "        for result in results:\n",
    "            writer.writerow(result)\n",
    "\n",
    "# Initialize Mondo adapter\n",
    "mondo = get_adapter(\"sqlite:obo:mondo\")\n",
    "\n",
    "# Iterate over each row in the 'o1_responses' DataFrame, with a progress bar\n",
    "for index, row in tqdm( o1_responses.iterrows(), total=len(o1_responses) ):\n",
    "    grounded_diagnoses_str = row['grounded_diagnosis']\n",
    "    \n",
    "    # Ensure grounded_diagnosis is deserialized from a string to a list\n",
    "    try:\n",
    "        grounded_diagnoses = ast.literal_eval(grounded_diagnoses_str)\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error parsing grounded diagnosis for index {index}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    metadata = row['metadata']  # Assuming this field exists in o1_responses\n",
    "    correct_disease = correct_answers_dict.get(metadata)  # Get correct ID from the dict\n",
    "    \n",
    "    if not correct_disease:\n",
    "        logging.warning(f\"No correct ID found for metadata: {metadata}\")\n",
    "        continue  # Skip rows with no correct ID\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Loop through each grounded diagnosis and score them\n",
    "    for rank, (disease_name, grounded_list) in enumerate(grounded_diagnoses, start=1):\n",
    "        for grounded_id, _ in grounded_list: # this is a list because there may be multiple groundings\n",
    "            grounded_score = score_grounded_result(grounded_id, correct_disease[0], mondo)\n",
    "            is_correct = grounded_score > 0 # Score > 0 means either exact or subclass match\n",
    "            \n",
    "            # Create a result row\n",
    "            result_row = [rank, disease_name, grounded_id, correct_disease, grounded_score, is_correct]\n",
    "            results.append(result_row)\n",
    "    \n",
    "    # Define the output file path\n",
    "    output_file = output_dir / f\"{metadata}.tsv\"\n",
    "    \n",
    "    # Write results to file\n",
    "    write_result_to_file(output_file, results)\n",
    "\n",
    "print(f\"Finished writing scored results to {output_dir}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "16bb848740f4d5e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_summary_statistics(input_dir, output_file, output_plot):\n",
    "    # Initialize the counter for each rank\n",
    "    rank_counter = Counter()\n",
    "\n",
    "    # Iterate through all files in the directory ending with .tsv\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.tsv'):\n",
    "            filepath = os.path.join(input_dir, filename)\n",
    "            # Read the TSV file\n",
    "            df = pd.read_csv(filepath, sep='\\t')\n",
    "\n",
    "            # Find the first occurrence of the correct diagnosis\n",
    "            correct_rank = df[df['is_correct'] == True].index.min() + 1 if not df[df['is_correct'] == True].empty else None\n",
    "\n",
    "            # Increment the appropriate counter based on the rank or nf if not found\n",
    "            if correct_rank is not None and 1 <= correct_rank <= 10:\n",
    "                rank_counter[f'n{correct_rank}'] += 1\n",
    "            else:\n",
    "                rank_counter['nf'] += 1\n",
    "\n",
    "    # Get the total number of records processed\n",
    "    total_files = sum(rank_counter.values())\n",
    "\n",
    "    # Prepare the row to be written to the output file (without the 'lang' column)\n",
    "    output_row = [\n",
    "        rank_counter.get('n1', 0),\n",
    "        rank_counter.get('n2', 0),\n",
    "        rank_counter.get('n3', 0),\n",
    "        rank_counter.get('n4', 0),\n",
    "        rank_counter.get('n5', 0),\n",
    "        rank_counter.get('n6', 0),\n",
    "        rank_counter.get('n7', 0),\n",
    "        rank_counter.get('n8', 0),\n",
    "        rank_counter.get('n9', 0),\n",
    "        rank_counter.get('n10', 0),\n",
    "        rank_counter.get('n10', 0) / total_files if total_files else 0,  # n10p: proportion of n10 hits\n",
    "        rank_counter.get('nf', 0)\n",
    "    ]\n",
    "\n",
    "    # Write the results to the output file (without 'lang' column)\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('n1\\tn2\\tn3\\tn4\\tn5\\tn6\\tn7\\tn8\\tn9\\tn10\\tn10p\\tnf\\n')\n",
    "        f.write('\\t'.join(map(str, output_row)) + '\\n')\n",
    "\n",
    "    print(f\"Summary statistics written to {output_file}\")\n",
    "\n",
    "    # Generate the plot\n",
    "    hits = ['Top-1', 'Top-3', 'Top-10']\n",
    "    percentages = [\n",
    "        rank_counter.get('n1', 0) / total_files * 100 if total_files else 0,\n",
    "        sum(rank_counter.get(f'n{i}', 0) for i in range(1, 4)) / total_files * 100 if total_files else 0,\n",
    "        sum(rank_counter.get(f'n{i}', 0) for i in range(1, 11)) / total_files * 100 if total_files else 0,\n",
    "    ]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(hits, percentages, color=['blue', 'green', 'orange'])\n",
    "    plt.xlabel('Hits')\n",
    "    plt.ylabel('Percent of cases')\n",
    "    plt.title('Top-k accuracy of correct diagnoses')\n",
    "    plt.ylim(0, 100)  # Adjust this as needed\n",
    "    plt.savefig(output_plot)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Plot saved to {output_plot}\")\n",
    "\n",
    "# Example usage in a Jupyter notebook:\n",
    "input_dir = \"../outputdir_all_2024_07_04/gpt_o1_disease_results\"\n",
    "output_file = \"../outputdir_all_2024_07_04/plots/topn_result_gpt_o1.tsv\"\n",
    "output_plot = \"../outputdir_all_2024_07_04/plots/topn_result_gpt_o1_plot.png\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# Call the function\n",
    "compute_summary_statistics(input_dir, output_file, output_plot)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9f2168282c6fd27c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
